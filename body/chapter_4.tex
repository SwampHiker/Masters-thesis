\newpage
\begin{center}
	\textbf{\large ГЛАВА 5}

	\textbf{\large НЕЙРОННЫЕ СЕТИ В ЗАДАЧЕ ПРЕДСКАЗАНИЯ ВЗАИМОДЕЙСТВИЯ БЕЛКОВ}
\end{center}
\refstepcounter{chapter}
\addcontentsline{toc}{chapter}{5. НЕЙРОННЫЕ СЕТИ В ЗАДАЧЕ ПРЕДСКАЗАНИЯ ВЗАИМОДЕЙСТВИЯ БЕЛКОВ}

В данной главе описаны нейронные сети, использованные и предлагаемые к использованию для решения задачи предсказания взаимодействия белков, а также подходы к процессу обучения таких сетей. Основные фокусы при проектировании таких сетей:
\begin{itemize}
\item Использование матриц косинусов для представления входных/выходных данных;
\item Применимость к данным различных размеров.
\end{itemize}

\section{Архитектура нейронных сетей}

\subsection{Полносвёрточная нейронная сеть FCN5}
Полносвёрточнная нейронная сеть\cite{fully_conv} -- это свёрточная нейронная сеть, в которой отсутствуют полносвязные слои. Как и все свёрточные сети, полносвёрточные сети позволяют эффективно обрабатывать изображения различных размерностей, наиболее часто - двумерных. Главной особенностью свёрточнных сетей без полносвязных слоёв является то, что они могут преобразовывать входные изображения практически любых размеров без масштабирования. Это крайне важное свойство при работе с матрицами косинусов, так как в отличие от графических изображений, их нельзя масштабировать. В рамках данной работы использовалась сеть FCN5, которая была разработана и использована еще в \cite{prip2023}. Несколько сетей FCN5 можно последовательно объединнить в одну большую, если это необходимо.

Сеть FCN5 состоит из 5 остаточных слоёв \cite{resnet}, 2 слоёв батч-нормализации \cite{batchnorm}, между слоями присутствуют \textit{пропускные связи}.

Используемые остаточные слои задаются количеством входных и выходных каналов, состоят из двух свёрточных слоёв, и организованы следующим образом:
\begin{enumerate}
\item Входной тензор поступает на первый свёрточный слой, который производит промежуточный тензор. Количество каналов в промежуточном тензоре равно количеству выходных канналов.
\item К промежуточный тензору применется функция активации ReLU, а результат поступает на выход второго свёрточного слоя. Второй свёрточный слой сохраняет количесвто каналов тензора.
Выход второго свёрточного слоя суммируется с промежуточным тензором (до применения ReLU), а к результату применяется функция активации LeakyReLU с параметром отрицательного склона равного 0,2 (функия активации не применняется для последнего остаточного блока в сети). Полученный тензор является выходом остаточного слоя.
\item Размер ядра используемых свёрток -- $3\times3$.
\item Для сохранения размеров (ширины и высоты) входных тензоров используется круговой паддинг. Использование других видов паддинга (нулевого, зеркального) не рекомендуется.
\end{enumerate}

Смысл пропускных связей (англ. \textit{skip connection}) заключается в том, чтобы отправлять на вход слоя нейронной сети не просто выход предыдущего слоя, но выход предыдущего слоя соединённый (коннкатенация каналов) с выходами еще более ранних слоёв. Общее устройство сети FCN5 можно увидеть на следующей схеме:
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{FCN5.png}
	\caption{Устройство сети FCN5.}
	\label{fig_fcn5}
\end{figure}

Сеть FCN5 по устройству крайне близка к сетям типа U-Net\cite{unet}. Но сеть U-Net известна тем, что количество каналов промежуточных тензоров сначала растёт, а потом убывает. При работе с FCN5, как и в большинстве других свёрточных сетей, количество каналов растёт от начала до конца.

Отметим, что количество каналов входного, а также количество выходных каналов в 5 остаточных слоях могут быть произвольными. В экспериментах часто использовалась следующая комбинация для промежуточных слоёв (входные каналы и пятый слой зависят от типа данных):
\begin{itemize}
\item Остаточный слой 1: 128 каналов;
\item Остаточный слой 2: 256 каналов;
\item Остаточный слой 3: 512 каналов;
\item Остаточный слой 4: 256, 384 или 512 каналов.
\end{itemize}
Для ускорения вычислений, также можно использовать уменьшенный вариант:
\begin{itemize}
\item Остаточный слой 1: 32 канала;
\item Остаточный слой 2: 64 канала;
\item Остаточный слой 3: 128 каналов;
\item Остаточный слой 4: 43 канала.
\end{itemize}

\subsection{Концепция сети-трансформера}
Основным недостатком полносвёрточных нейронных сетей является то, хоть они и могут обрабатывать изображения сколь угодно больших размеров (на сколько то позволяет память компьютера), для изображений крайне малого размера (которые в рамках данного исследования могут возникнуть при работе с пептидами), может оказаться, что применяемых свёрток слишком много (каждая свёртка уменьшает размер изображения, после чего операция паддинга возвращает исходный размер), и результат окажется совершенно ненадёжным. Также отметим, что операция свёртки локальна -- за формирования одного пикселя выходнного изображения отвечает ограниченная область вокруг этого пикселя в исходнном изображении. Это значит, что практически отстутствует связь между удалёнными участками изображения.

Наиболее привлекательным решением таких проблем выглядит использование сети-трансформера\cite{attention_all_you_need}. Такие сети в настоящее время получили крайне широкое распространение, прежде всего в задачах обработки естественного языка, но также и в задачах биоинформатики. Сети-трансформеры хорошо работают с данными, представленными в виде последовательностей, позволяют эффективно находить связи между удалёнными участками таких последовательностей.

Концептуально, в такой сети можно использовать токен, бинарнно кодирующий 5 аминокислотных остатков и релятивистскую матрицу косинусов размера $4\times4$. На выходе можно, например, получать токены с матрицами косинусов $4\times4$, кодирующими матричное поле. Можно использовать и более простые выходные токены.

\section{Представление данных и процесс обучения нейронной сети}

\subsection{Набор данных}

\subsection{Процесс обучения}
