\newpage
\begin{center}
	\textbf{\large 1. МАТРИЦЫ КОСИНУСОВ}
\end{center}
\refstepcounter{chapter}
\addcontentsline{toc}{chapter}{1. МАТРИЦЫ КОСИНУСОВ}

Матрицы косинусов как математический объект были предложены ранее в рамках курсовых и дипломной работ. Теоретические результаты предыдущих работ здесь будут изложены, по возможности, кратко и без доказательств, но систематично. Здесь они необходимы, прежде всего, для правильного изложения новых результатов, касающихся нового объекта --- релятивистской матрицы косинусов. Кроме того, терминология данной главы может местами отличаться от терминологии предыдущих работ, что связано с тем, что она ещё не устоялась, и требует некоторых изменений для большей систематичности.

\section{Базовые определения}

Пусть имеется некоторое гильбертово пространство $\mathcal{H}$ (в частном случае некоторое конечномерное евклидово пространство $\mathbb{R}^{k}$).
Пусть в данном пространстве задана последовательность точек (ломаная) $X = (\vec{x}_i)$, где $i = \overline{0,n}$. Обозначим $\vec{p}_{i} = \vec{x}_i - \vec{x}_{i-1}$, где $i = \overline{1,n}$, тогда \textit{ненормализованной матрицей косинусов} по ломаной $X$ будем называть квадратную матрицу вида:

\begin{equation}
	{C}_{E} = {(<\vec{p}_{i}, \vec{p}_{j}>)}_{ij} \in \mathbb{R}_{n,n}.
	\label{C_E_definition}
\end{equation}

Если выполняется условие:

\begin{equation}
	||\vec{p}_{i}|| = 1, i = \overline{1,n},
	\label{normalized_definition}
\end{equation}

то говорят о \textit{нормализованных матрицах косинусов} или собственно \textit{матрицах косинусов}. На практике, удобнее всего работать с нормализованными матрицами косинусов, ненормализованные матрицы косинусов могут возникнуть при некоторых операциях над обычными матрицами косинусов. Далее в работе, если не оговорено противное, будет подразумеваться наличие нормализации. 

Название матриц следует из того факта, что при условии \ref{normalized_definition}:

\begin{equation}
	{C}_{E} = {(<\vec{p}_{i}, \vec{p}_{j}>)}_{ij} = {(||\vec{p}_{i}|| ||\vec{p}_{j}|| \cos{\vec{p}_{i} \wedge \vec{p}_{j}})}_{ij} = {(\cos{\vec{p}_{i} \wedge \vec{p}_{j}})}_{ij}.
	\label{name_cosine}
\end{equation}

Объект, определенный выше, строится по и описывает одну ломаную. Пусть имеется две последовательности точек: $X' = (\vec{x'}_{i})$, где $i = \overline{0,m}$ и $X'' = (\vec{x''}_{j})$, где $j = \overline{0,n}$. Тогда аналогично \ref{C_E_definition} можно построить матрицу косинусов по двум ломаным $X'$ и $X''$:

\begin{equation}
	{C}_{X',X''} = {(<\vec{p'}_{i}, \vec{p''}_{j}>)}_{ij} \in \mathbb{R}_{m,n}.
	\label{C_X1X2_definition}
\end{equation}

Определения \ref{C_E_definition} и \ref{C_X1X2_definition} здесь фундаментальны, на практике полезны также матрица косинусов, кодирующая поворот ломаной $C_A$, и кодирующая вектор относительно ломаной ${C}_{\nu}$ --- они являются частными случаями \ref{C_X1X2_definition}. Здесь определим ${C}_{\nu}$, в следующей секции --- $C_A$:

Пусть задан некоторый вектор $\vec{\nu} \in \mathbb{R}^k$ и $X = (\vec{x}_{i})$ с $i = \overline{0,m}$, тогда \textit{матрицей косинусов кодирующей вектор} назовём матрицу вида:

\begin{equation}
	{C}_{\nu} = {(<\vec{p}_{i}, \vec{\nu}>)}_{ij} \in \mathbb{R}_{m,n}.
	\label{C_nu_definition}
\end{equation}

Здесь $n \ge 1$ не зависит от ни от $X$, ни от $\vec{\nu}$, а выбирается из других практических соображений.

Непрерывным обобщение матрицы косинусов можно назвать \textit{поверхностью косинусов}. Пусть $x(\alpha)$ - гладкая кривая $x : [0, l] \rightarrow \mathcal{H}$ и $\vec{p}(\alpha) = \frac{\partial{x(\alpha)}}{\partial{\alpha}}$. Тогда \ref{C_E_definition} можно переписать как:

\begin{equation}
	C({\alpha}_1, {\alpha}_2) = <\vec{p}(\alpha_1), \vec{p}(\alpha_2)>.
	\label{C_E_definition_cont}
\end{equation}

Таким образом, получаем действительную функцию о двух параметров $C : [0, l] \times [0, l] \rightarrow \mathbb{R}$.
Условие нормализации для \ref{C_E_definition_cont} выглядит следующим образом:

\begin{equation}
	||\vec{p}(\alpha)|| = 1, \forall{i} \in [0, l].
	\label{normalized_definition_cont}
\end{equation}

Использование непрерывной \ref{C_E_definition_cont} для вычислений затруденено. Гораздо удобнее исследовать и использовать матрицы.

\section{Свойства матриц косинусов}

Для исследования свойств описанных матриц, необходимо записать их в более удобном виде. Пусть речь идёт об евклидовом простанстве $\mathbb{R}^{k}$, тогда в нём можно ввести репер $O = (x_0, \vec{v}_1, ..., \vec{v}_k)$, пораждающий декартову систему координат. Тогда каждой точке $x_i$ и вектору $\vec{p}_i$ можно поставить в соответствие координатный вектор-столбец $p_i \in \mathbb{R}_{k,1}$. Полученные столбцы координат $p_i$ можно объединить в матрицу $P = [p_1, ..., p_k] \in \mathbb{R}_{n}$. Тогда \ref{C_E_definition} и \ref{C_X1X2_definition} можно переписать как:

\begin{equation}
	C_E = P^\mathrm{T}P,
	\label{C_E_calc}
\end{equation}

\begin{equation}
	C_{X_1, X_2} = {P_1}^\mathrm{T}{P_2}.
	\label{C_X1X2_calc}
\end{equation}

\subsection{Базовые свойства}

Приведём основные свойства матриц косинусов (без доказательств):
\begin{enumerate}
\item Все значения матриц косинусов лежат на отрезке $[-1, 1]$;
\item Все диагональные элементы матрицы $C_E$ равны $1$;
\item Матрицы косинусов не зависят от выбора системы координат;
\item Ранг матрицы $C_E$ равен размерности ломаной $X$;
\item Матрица $C_E$ - симметричная. Все её собственные значения неотрицательны, и в сумме равны $n$;
\item Ломаную $X$ (ломаные $X_1$ и $X_2$) можно восстановить из $C_E$ ($C_{X_1, X_2}$) с точностью до выбора системы координат, причём как для нормированных, так и для ненормированных матриц (в случае последних с $C_{X_1, X_2}$ необходимо знание длин векторов $\vec{p}_i$).
\end{enumerate}

\subsection{Восстановление исходных ломаных}

Последнее свойство наиболее важно, так как оно позволяет использовать матрицы косинусов как инвариантное представление геометричеких ломаных (что крайне полезно при исследовании белковых молекул и их взаимодействий). Зная \label{C_E_calc} и \label{C_X1X2_calc} легко построить соответсвующие матрицы. Ниже приведём без доказательств алгоритмы, которые позволяют строить ломаные по этим матрицам:

\begin{enumerate}
\item \textit{Восстановление $X$ из $C_E$}

Из описанного выше свойства 5 следует, что матрица $C_E$ будет обладать $k$ неотрицательными собственными значениями $\lambda_1, ..., \lambda_k$ и собственными векторами $v_1, ..., v_k \in \mathbb{R}_{n,1}$. Тогда в некоторой системе координат матрица $P$ примет вид:

\begin{equation}
	P = \diag(\sqrt{\lambda_1}, ..., \sqrt{\lambda_k}){[v_1, ..., v_k]}^\mathrm{T}.
	\label{X_from_C_E_extraction}
\end{equation}

Где координаты точек ломаной $X$ восстанавливаются из $P$ через кумулятивную сумму. Формула \ref{X_from_C_E_extraction} работает и для ненормализованных матриц.

\item \textit{Восстановление $X_2$ из $C_{X_1, X_2}$ при известном $X_1$}

Введём следующую крайне важную матрицу:

\begin{equation}
	T_P = {(P{P}^\mathrm{T})}^{-1}P,
	\label{T_definition}
\end{equation}

данная матрица (с поправкой на транспонирование) представляет собой матрицу вычисления параметров линейной регрессии. Из \ref{C_X1X2_calc} и \ref{T_definition} следует, что:

\begin{equation}
	T_{P_1}C_{X_1, X_2} = {(P_1{P_1}^\mathrm{T})}^{-1}P_1{P_1}^\mathrm{T}{P_2} = P_2,
	\label{X2_from_C_X1X2_extraction_known_X1}
\end{equation}

данная формула позволяет посчитать $P_2$ из $C_{X_1, X_2}$ при известном $P_1$, из которого, с помощью кумулятивной суммы, можно получить $X_2$. Формула \ref{X2_from_C_X1X2_extraction_known_X1}, опять же, работает и для ненормализованных матриц.

\item \textit{Восстановление $X_1$ и $X_2$ из $C_{X_1, X_2}$}

Для выполнения данной операций существует следующий алгоритм, доказательство которого было приведено в предыдущей работе:

\begin{algorithmic}
\STATE 1. let \(X_1\) be matrix of \(C_{P_1,P_2}C^\mathrm{T}_{P_1,P_2}\) eigenvectors and \({X_2}\) be matrix of \(C^\mathrm{T}_{P_1,P_2}C_{P_1,P_2}\) eigenvectors
\STATE 2. let \(Y_1 \gets X^\mathrm{T}_1 C_{P_1,P_2}\) and \(Y_2 \gets (C_{P_1,P_2} X_2)^\mathrm{T}\)
\STATE 3. let \(Z_1 \gets T_{Y_2} C_{P_1,P_2} T^\mathrm{T}_{Y_1}\)
\STATE 4. let \(Z_2\) be matrix of \(Y_1 Y^\mathrm{T}_1\) eigenvectors
\STATE 5. let \(Z_3 \gets Z^\mathrm{T}_2 Z_1 Y_2\)
\STATE 6. sum \(T_{[Z_3]^2}\) along rows into a column-vector \(s\)
\STATE 7. let \(\hat{P}_1\) be \(diag(sqrt(s)) Z_3\) with normalized column-vectors
\STATE 8. let \(\hat{P}_2\) be \(T_{\hat{P}_1} C_{P_1,P_2}\) with normalized column-vectors
\end{algorithmic}

[здесь перевести и оформить - мне пока лень]

\end{enumerate}
 
\subsection{Арифметические свойства матриц косинусов}

TO DO

\subsection{Применение матриц косинусов}

TO DO

\section{Релятивистская матрица косинусов}

В данном разделе представлен полностью новый результат, касающийся матриц косинусов.  \textit{Релятивистская матрица косинусов $C_{rel}$} отличается от обычной $C_E$ тем, что позволяет закодировать не только лишь некоторую последовательность точек, но точку, из которой эта последовательность наблюдается. Таким образом получается инвариантное относительно выбора декартовой системы координат (а вообще говоря --- Лоренц-инвариантное) представление пары точка-ломаная, что позволяет задавать функции (поля), порождаемые ломаной (белковой молекулой), как преобразования матриц косинусов. Для релятивистских матриц будет дано полное определение, в соответствии со специальной теорией относительности (СТО), и приближённая запись, используемая на практике.

\subsection{Полное определение}

Пусть существует некоторая последовательность точек $X$, точки которой перемещаются в пространстве $\mathbb{R}^{k}$ со скоростями, не превышающими скорость света $c$:

$X(t) = (\vec{x}_{i}(t))$, где $i = \overline{0,n}$;

$\vec{x}_i : \mathbb{R} \rightarrow \mathbb{R}^{k}$;

$||\frac{\partial{\vec{x}_i}}{\partial{t}}|| < c$.

Следуя Минковскому [ref!], в пространстве-времени можно ввести систему координат, в которой точке $\vec{x}_i$ в момент времени $t$ будет поставлен в соответствие вектор-столбец $x_i = [x^1_i(t), ..., x^k_i(t), ict]^\mathrm{T} \in \mathbb{C}_{k+1,1}$.

Пусть имеется некоторая точка $\vec{x}_{ref}$ и момент времени $t_{ref}$, из которых наблюдается ломаная $X$. Этой точке в пространстве-времени соответствуют координаты $x_{ref} = [x^1_{ref}(t), ..., x^k_{ref}(t), ict_{ref}]^\mathrm{T}$. Каждая точка из $X$ будет наблюдаться в $\vec{x}_{ref}$ в момент $t_{ref}$ при пересечении траектории $\vec{x}_i(t)$ и светового конуса, порождённого $\vec{x}_{ref}$ и $t_{ref}$. Из того, что все скорости не превышают $c$, следует, что такое пересечение единственно, и для каждой точки $\vec{x}_i$ произойдёт в некоторый момент времени $t^*_i \le t_{ref}$. Таким образом, в $\vec{x}_{ref}$ в момент $t_{ref}$ будет наблюдаться $X^*$ - образ ломаной $X(t)$ вида:
$X^* = (\vec{x}^*_i)$, где $i = \overline{0,n}$ и координаты $\vec{x}^*_i$ равны $x^*_i = [x^1_i(t^*_i), ..., x^k_i(t^*_i), ict^*_i]^\mathrm{T}$.

Если теперь посчитать $\vec{p}_i = \vec{x}^*_i - \vec{x}^*_{i-1}$ и использовать произведение Минковского, \ref{C_E_definition} или \ref{C_E_calc} можно получить \textit{релятивистскую матрицу косинусов}:

\begin{equation}
	C_{rel} = {(<\vec{p}_{i}, \vec{p}_{j}>)}_{ij} = {\left(\sum_{s=1}^{k} p^s_i p^s_j - c^2(t^*_i - t^*_{i-1})(t^*_j - t^*_{j-1})\right)}_{ij} \in \mathbb{R}_{n,n}.
	\label{C_rel_definition}
\end{equation}

\subsection{Упрощённая формулировка}

Теперь, для упрощения, положим, что $\forall{i}: \vec{x}_i(t) = \vec{x}_i = const$. Также, не нарушая общности, положим $t_{ref} = 0$. При таких предположениях вычисление пересечения светового конуса и траекторий заметно упростится, и можно будет записать:

\begin{equation}
	t^*_i = t_{ref} - \frac{||\vec{x}_i - \vec{x}_{ref}||}{c} = -\frac{1}{c}\sqrt{\sum_{s=1}^{k}(x^s_i - x^s_{ref})^2},
	\label{t_formula}
\end{equation}

и на основании \ref{t_formula} получим следующие значения координат:

\begin{equation}
	x^*_i = \begin{bmatrix} x^1_i \\ ... \\ x^k_i \\ -i\sqrt{\sum_{s=1}^{k}(x^s_i - x^s_{ref})^2} \end{bmatrix}.
	\label{x_formula}
\end{equation}

По \ref{x_formula} можно посчитать $P = \begin{bmatrix} P_x \\ -id \end{bmatrix} \in \mathbb{C}_{k+1,n}$ и по \ref{C_E_calc} посчитать:

\begin{equation}
	C_{rel} = {\begin{bmatrix} P_x \\ -id \end{bmatrix}}^\mathrm{T}\begin{bmatrix} P_x \\ -id \end{bmatrix} = P^\mathrm{T}_xP_x - d^\mathrm{T}d \in \mathbb{R}_{n,n}.
	\label{C_rel_definition_practical}
\end{equation}

В случае, когда $||\frac{\partial{\vec{x}_i}}{\partial{t}}|| << c$ разница между $\vec{x}_i(t^*_i)$ и $\vec{x}_i(t_{ref})$ будет иметь порядок вычислительной погрешности, а следовательно  использование \ref{C_rel_definition} неоправдано. Далее свойства матриц косинусов будем исследовать исключительно на основе \ref{C_rel_definition_practical}.

\subsection{Свойства релятивистских матриц косинусов}

TO DO

